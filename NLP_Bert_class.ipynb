{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangying9/NLP/blob/main/NLP_Bert_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfIMtw6BaiO1"
      },
      "source": [
        "## Pandas DataFrame: Create from lists of values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "3an6F95jRQcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "JF93rDLmRdq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "C6UK6kWgRgY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW"
      ],
      "metadata": {
        "id": "DTVcojvkRw3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "TZcouOnPR0qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "wmwvoCqTTyer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a DataFrame 'df' with columns 'text' and 'label' for your data\n",
        "# Load and preprocess your dataset\n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['spam_class.csv']),encoding = \"ISO-8859-1\")  # Change 'spam_data.csv' to your actual file name"
      ],
      "metadata": {
        "id": "WRFRguabT-1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['label'] = df['Label'].map({'spam': 1, 'ham': 0})  # Convert labels to numerical values"
      ],
      "metadata": {
        "id": "RaiIUwOWTUDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text data\n",
        "max_len = 128  # Max length of input sequence\n",
        "input_ids = []\n",
        "attention_masks = []"
      ],
      "metadata": {
        "id": "NjUTcme1S_vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=0\n",
        "for text in df['Messages']:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = max_len,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "    input_ids.append(encoded_dict['input_ids']) # paddings are 0\n",
        "    attention_masks.append(encoded_dict['attention_mask'])# using 1 and 0 indicates the encodes and paddings\n",
        "\n",
        "    n+=1\n",
        "    if n<5:\n",
        "      print(f'In loop number {n}, the shape of encoded_dict is {np.array(encoded_dict).shape}\\n')\n",
        "      print(f'In loop number {n}, the inputID is {input_ids}\\n')\n",
        "      print(f'In loop number {n}, the attention_masks is {attention_masks}\\n')\n"
      ],
      "metadata": {
        "id": "OKZR74QsTDNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(input_ids).shape,np.array(attention_masks).shape,len(df)"
      ],
      "metadata": {
        "id": "2u3PKPo7X6sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert 3 dims to 2 dims\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "metadata": {
        "id": "QuIqTWWbYeUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(input_ids).shape,np.array(attention_masks).shape,len(df)"
      ],
      "metadata": {
        "id": "wa_cICxWYgWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = torch.tensor(df['label'].values)"
      ],
      "metadata": {
        "id": "0iVI3mSlTGlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(labels)"
      ],
      "metadata": {
        "id": "wEXb5e6RaFUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(labels).shape"
      ],
      "metadata": {
        "id": "IlyOZuXSaIgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training, validation, and test sets\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(input_ids, labels, random_state=42, test_size=0.1)\n",
        "train_masks, test_masks, _, _ = train_test_split(attention_masks, labels, random_state=42, test_size=0.1)"
      ],
      "metadata": {
        "id": "pQlQg9uQaWsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs.shape, test_inputs.shape, train_labels.shape, test_labels.shape"
      ],
      "metadata": {
        "id": "_63jt3hOaYWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks.shape, test_masks.shape"
      ],
      "metadata": {
        "id": "IW4_SEvwajtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch DataLoader\n",
        "batch_size = 32\n",
        "train_data = torch.utils.data.TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = torch.utils.data.RandomSampler(train_data)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = torch.utils.data.TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = torch.utils.data.SequentialSampler(test_data)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "Ost4NJM_aqlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data )"
      ],
      "metadata": {
        "id": "KmSqYcsRauoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(train_dataloader).shape"
      ],
      "metadata": {
        "id": "PRg99MClbfHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the BERT model\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "num_epochs = 3"
      ],
      "metadata": {
        "id": "RsuVhOvFbGzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):#3\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()#zero gradients before backpropogation\n",
        "        #unpack the elements of batch tuple\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss # output loss\n",
        "        total_loss += loss.item()#accumulate loss in each epoch\n",
        "        loss.backward() #perform backward propogation based on the loss\n",
        "        optimizer.step()#updates parameter using computing gradients and optimizer AdamW\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)#average across total number of batches\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {avg_train_loss}')"
      ],
      "metadata": {
        "id": "JPZSvRqzbKpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "\"\"\"In evaluation mode, the model behaves differently compared to training mode. For example,\n",
        "dropout layers are disabled, and batch normalization layers use running statistics instead of batch statistics.\"\"\"\n",
        "model.eval()\n",
        "preds = []\n",
        "true_labels = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    input_ids, attention_mask, labels = batch\n",
        "    with torch.no_grad():#gradients are not computed, which can save memory and computational resources\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    \"\"\"retrieves the logits (raw output scores) from the output of the model.\n",
        "    The logits represent the model's predictions before applying the softmax activation function.\"\"\"\n",
        "    logits = outputs.logits\n",
        "    preds.extend(logits.argmax(dim=1).cpu().numpy())#extracts the predicted labels from the logits by taking the index of the maximum value along dimension 1 (which represents the classes).\n",
        "    true_labels.extend(labels.cpu().numpy()) #extracts the true labels from the batch\n",
        "\n",
        "accuracy = accuracy_score(true_labels, preds)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "4TMmPHNKbue7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def predict_spam(text, model, tokenizer, max_len=128):\n",
        "    # Tokenize the text\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predicted_label = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    # Map numerical label back to original label\n",
        "    label_map = {1: 'spam', 0: 'ham'}\n",
        "    predicted_label = label_map[predicted_label]\n",
        "\n",
        "    return predicted_label"
      ],
      "metadata": {
        "id": "0MGu6TJ-bzcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'model' and 'tokenizer' are already loaded and trained\n",
        "text_to_predict = \"Congratulations! You've won a free vacation. Click here to claim your prize!\"\n",
        "predicted_label = predict_spam(text_to_predict, model, tokenizer)\n",
        "print(\"Predicted Label:\", predicted_label)"
      ],
      "metadata": {
        "id": "D45-8K0Lb1Qc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}